{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f822713-3df4-4d35-a45d-a9fc89824add",
   "metadata": {},
   "source": [
    "## loading in packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e869526-eae6-41a0-9c44-6dab89be2dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import trim, lower, regexp_replace, col, udf\n",
    "from pyspark.sql.types import StringType\n",
    "import nltk\n",
    "import re\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328cb487-56d6-4586-a8b9-5ef46e1a1132",
   "metadata": {},
   "source": [
    "### starting spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d955ff5f-ba9f-4c6d-b81a-470ce8776d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:20:24 WARN Utils: Your hostname, DESKTOP-25IG4QD resolves to a loopback address: 127.0.1.1; using 172.18.229.145 instead (on interface eth0)\n",
      "24/05/27 01:20:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/27 01:20:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/05/27 01:20:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/05/27 01:21:53 WARN TaskSetManager: Stage 0 contains a task of very large size (2746 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+--------+-------------------+-----+-----------+--------------+\n",
      "|Invoice|StockCode|         Description|Quantity|        InvoiceDate|Price|Customer ID|       Country|\n",
      "+-------+---------+--------------------+--------+-------------------+-----+-----------+--------------+\n",
      "| 489434|    85048|15CM CHRISTMAS GL...|      12|2009-12-01 07:45:00| 6.95|    13085.0|United Kingdom|\n",
      "| 489434|   79323P|  PINK CHERRY LIGHTS|      12|2009-12-01 07:45:00| 6.75|    13085.0|United Kingdom|\n",
      "| 489434|   79323W| WHITE CHERRY LIGHTS|      12|2009-12-01 07:45:00| 6.75|    13085.0|United Kingdom|\n",
      "| 489434|    22041|RECORD FRAME 7\" S...|      48|2009-12-01 07:45:00|  2.1|    13085.0|United Kingdom|\n",
      "| 489434|    21232|STRAWBERRY CERAMI...|      24|2009-12-01 07:45:00| 1.25|    13085.0|United Kingdom|\n",
      "+-------+---------+--------------------+--------+-------------------+-----+-----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:21:54 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/05/27 01:21:55 WARN TaskSetManager: Stage 1 contains a task of very large size (2746 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/05/27 01:21:57 WARN TaskSetManager: Stage 4 contains a task of very large size (2746 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------------+------------------+------------------+-----------+-----------+\n",
      "|summary|           Invoice|         StockCode|         Description|          Quantity|             Price|Customer ID|    Country|\n",
      "+-------+------------------+------------------+--------------------+------------------+------------------+-----------+-----------+\n",
      "|  count|            525461|            525461|              525461|            525461|            525461|     525461|     525461|\n",
      "|   mean| 514496.9241788484| 30518.37992495103|                 NaN|10.337667305470815| 4.688834478677414|        NaN|       NULL|\n",
      "| stddev|14439.209494465998|20693.168152854683|                 NaN| 107.4241102687977|146.12691395292643|        NaN|       NULL|\n",
      "|    min|            489434|             10002|  DOORMAT UNION J...|             -9600|         -53594.36|    12346.0|  Australia|\n",
      "|    max|           C538164|                 m|          wrong invc|             19152|          25111.09|        NaN|West Indies|\n",
      "+-------+------------------+------------------+--------------------+------------------+------------------+-----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:21:59 WARN TaskSetManager: Stage 7 contains a task of very large size (2746 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------------+------------------+------------------+-----------+-----------+\n",
      "|summary|           Invoice|         StockCode|         Description|          Quantity|             Price|Customer ID|    Country|\n",
      "+-------+------------------+------------------+--------------------+------------------+------------------+-----------+-----------+\n",
      "|  count|            525461|            525461|              525461|            525461|            525461|     525461|     525461|\n",
      "|   mean| 514496.9241788484| 30518.37992495103|                 NaN|10.337667305470815| 4.688834478677414|        NaN|       NULL|\n",
      "| stddev|14439.209494465998|20693.168152854683|                 NaN| 107.4241102687977|146.12691395292643|        NaN|       NULL|\n",
      "|    min|            489434|             10002|  DOORMAT UNION J...|             -9600|         -53594.36|    12346.0|  Australia|\n",
      "|    25%|          501879.0|           21528.0|                 NaN|                 1|              1.25|    14375.0|       NULL|\n",
      "|    50%|          514826.0|           22172.0|                 NaN|                 3|               2.1|    16110.0|       NULL|\n",
      "|    75%|          527297.0|           22652.0|                 NaN|                10|              4.21|    17865.0|       NULL|\n",
      "|    max|           C538164|                 m|          wrong invc|             19152|          25111.09|        NaN|West Indies|\n",
      "+-------+------------------+------------------+--------------------+------------------+------------------+-----------+-----------+\n",
      "\n",
      "525461\n",
      "+-------+---------+--------------------+--------+-------------------+-----+-----------+--------------+\n",
      "|Invoice|StockCode|         Description|Quantity|        InvoiceDate|Price|Customer ID|       Country|\n",
      "+-------+---------+--------------------+--------+-------------------+-----+-----------+--------------+\n",
      "| 536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00| 2.55|    17850.0|United Kingdom|\n",
      "| 536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00| 3.39|    17850.0|United Kingdom|\n",
      "| 536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00| 2.75|    17850.0|United Kingdom|\n",
      "| 536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00| 3.39|    17850.0|United Kingdom|\n",
      "| 536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00| 3.39|    17850.0|United Kingdom|\n",
      "+-------+---------+--------------------+--------+-------------------+-----+-----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:22:00 WARN TaskSetManager: Stage 10 contains a task of very large size (2836 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/05/27 01:22:00 WARN TaskSetManager: Stage 11 contains a task of very large size (2836 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/05/27 01:22:01 WARN TaskSetManager: Stage 14 contains a task of very large size (2836 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+--------------------+------------------+-----------------+-----------+-----------+\n",
      "|summary|          Invoice|         StockCode|         Description|          Quantity|            Price|Customer ID|    Country|\n",
      "+-------+-----------------+------------------+--------------------+------------------+-----------------+-----------+-----------+\n",
      "|  count|           541910|            541910|              541910|            541910|           541910|     541910|     541910|\n",
      "|   mean|559965.7926209917|27623.240210938104|                 NaN| 9.552233765754462|4.611138332934094|        NaN|       NULL|\n",
      "| stddev|13428.43735533339| 16799.73762842769|                 NaN|218.08095694392486|96.75976549366531|        NaN|       NULL|\n",
      "|    min|           536365|             10002| 4 PURPLE FLOCK D...|            -80995|        -11062.06|    12346.0|  Australia|\n",
      "|    max|          C581569|                 m|   wrongly sold sets|             80995|          38970.0|        NaN|Unspecified|\n",
      "+-------+-----------------+------------------+--------------------+------------------+-----------------+-----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:22:03 WARN TaskSetManager: Stage 17 contains a task of very large size (2836 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+--------------------+------------------+-----------------+-----------+-----------+\n",
      "|summary|          Invoice|         StockCode|         Description|          Quantity|            Price|Customer ID|    Country|\n",
      "+-------+-----------------+------------------+--------------------+------------------+-----------------+-----------+-----------+\n",
      "|  count|           541910|            541910|              541910|            541910|           541910|     541910|     541910|\n",
      "|   mean|559965.7926209917|27623.240210938104|                 NaN| 9.552233765754462|4.611138332934094|        NaN|       NULL|\n",
      "| stddev|13428.43735533339| 16799.73762842769|                 NaN|218.08095694392486|96.75976549366531|        NaN|       NULL|\n",
      "|    min|           536365|             10002| 4 PURPLE FLOCK D...|            -80995|        -11062.06|    12346.0|  Australia|\n",
      "|    25%|         547906.0|           21929.0|                 NaN|                 1|             1.25|    14367.0|       NULL|\n",
      "|    50%|         560689.0|           22569.0|                 NaN|                 3|             2.08|    16245.0|       NULL|\n",
      "|    75%|         571841.0|           23165.0|                 NaN|                10|             4.13|        NaN|       NULL|\n",
      "|    max|          C581569|                 m|   wrongly sold sets|             80995|          38970.0|        NaN|Unspecified|\n",
      "+-------+-----------------+------------------+--------------------+------------------+-----------------+-----------+-----------+\n",
      "\n",
      "541910\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Online Retail Data Cleaning\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read the Excel file using pandas\n",
    "file_path = 'online_retail_II 2.xlsx'\n",
    "retail_dfs1 = pd.read_excel(file_path, sheet_name=0)\n",
    "retail_dfs2 = pd.read_excel(file_path, sheet_name=1)\n",
    "# Convert the pandas DataFrame to a Spark DataFrame\n",
    "retails1_spark = spark.createDataFrame(retail_dfs1)\n",
    "retails2_spark = spark.createDataFrame(retail_dfs2)\n",
    "\n",
    "retails1_spark.show(5)                # Show the first 5 rows\n",
    "retails1_spark.describe().show()      # Compute basic statistics for numeric columns\n",
    "retails1_spark.summary().show()       # Compute summary statistics for columns\n",
    "print(retails1_spark.count())  \n",
    "\n",
    "retails2_spark.show(5)                # Show the first 5 rows\n",
    "retails2_spark.describe().show()      # Compute basic statistics for numeric columns\n",
    "retails2_spark.summary().show()       # Compute summary statistics for columns\n",
    "print(retails2_spark.count())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2988c48c-d5e5-44dd-a2c4-6ab7ed67fbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:22:03 WARN TaskSetManager: Stage 20 contains a task of very large size (2746 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:22:03 WARN TaskSetManager: Stage 23 contains a task of very large size (2746 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:22:03 WARN TaskSetManager: Stage 26 contains a task of very large size (2746 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/05/27 01:22:05 WARN TaskSetManager: Stage 32 contains a task of very large size (2746 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410763\n",
      "400916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:22:05 WARN TaskSetManager: Stage 38 contains a task of very large size (2746 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:22:06 WARN TaskSetManager: Stage 44 contains a task of very large size (2746 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:22:07 WARN TaskSetManager: Stage 50 contains a task of very large size (2836 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:22:07 WARN TaskSetManager: Stage 53 contains a task of very large size (2836 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:22:07 WARN TaskSetManager: Stage 56 contains a task of very large size (2836 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:22:08 WARN TaskSetManager: Stage 62 contains a task of very large size (2836 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:22:08 WARN TaskSetManager: Stage 68 contains a task of very large size (2836 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:22:08 WARN TaskSetManager: Stage 74 contains a task of very large size (2836 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:22:09 WARN TaskSetManager: Stage 80 contains a task of very large size (2746 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/05/27 01:22:10 WARN TaskSetManager: Stage 86 contains a task of very large size (2836 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400916 392693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/27 01:22:10 WARN TaskSetManager: Stage 92 contains a task of very large size (2746 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/05/27 01:22:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/05/27 01:22:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/27 01:22:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/27 01:22:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/27 01:22:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/27 01:22:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/27 01:22:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/27 01:22:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/27 01:22:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/05/27 01:22:13 WARN TaskSetManager: Stage 95 contains a task of very large size (2836 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/05/27 01:22:13 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "24/05/27 01:22:13 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/27 01:22:14 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/27 01:22:14 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/27 01:22:14 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "24/05/27 01:22:14 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "24/05/27 01:22:14 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "24/05/27 01:22:14 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "24/05/27 01:22:14 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Define a function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    other_words = {'set', 'of','/', '-',\"'s\", '\"s','cm','m','.','s','and','to'}\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_words = [word for word in words if word.lower() not in other_words]\n",
    "    rejoined_words = ' '.join(filtered_words)\n",
    "    rejoined_words = re.sub(r's/(\\d+)', r'\\1', rejoined_words)\n",
    "    rejoined_words = re.sub(r'set/(\\d+)', r'\\1', rejoined_words)\n",
    "\n",
    "    return rejoined_words\n",
    "\n",
    "# Register the function as a UDF\n",
    "remove_stopwords_udf = udf(remove_stopwords, StringType())\n",
    "\n",
    "# Data Cleaning Steps\n",
    "def clean_df(spark_df):\n",
    "    print(spark_df.count())\n",
    "    # Handle missing values\n",
    "    clean_spark_df = spark_df.dropna()\n",
    "    print(clean_spark_df.count())\n",
    "\n",
    "    # Remove duplicate rows\n",
    "    clean_spark_df = clean_spark_df.dropDuplicates()\n",
    "    print(clean_spark_df.count())\n",
    "    \n",
    "    # Correct data types\n",
    "    clean_spark_df = clean_spark_df.withColumn(\"InvoiceDate\", col(\"InvoiceDate\").cast(\"timestamp\"))\n",
    "    clean_spark_df = clean_spark_df.withColumn(\"Customer ID\", col(\"Customer ID\").cast(\"integer\"))\n",
    "\n",
    "    # Remove negative or zero quantities and prices\n",
    "    clean_spark_df = clean_spark_df.filter((col(\"Quantity\") > 0) & (col(\"Price\") > 0))\n",
    "    print(clean_spark_df.count())\n",
    "\n",
    "    # Standardize text data in 'Description'\n",
    "    clean_spark_df = clean_spark_df.withColumn(\"Description\", trim(lower(col(\"Description\"))))\n",
    "    print(clean_spark_df.count())\n",
    "    \n",
    "    clean_spark_df = clean_spark_df.withColumn(\"Description\", regexp_replace(col(\"Description\"), ' [^a-zA-Z] ', ''))\n",
    "    clean_spark_df = clean_spark_df.withColumn(\"Description\", remove_stopwords_udf(col(\"Description\")))\n",
    "    # clean_spark_df = clean_spark_df.withColumn(\"Description\", regexp_replace(col(\"Description\"), '[0-9]',''))\n",
    "    # Ensure consistency in Customer IDs (e.g., remove anomalies)\n",
    "    clean_spark_df = clean_spark_df.filter(col(\"Customer ID\").isNotNull() & (col(\"Customer ID\") > 0))\n",
    "    print(clean_spark_df.count())\n",
    "\n",
    "    # Remove invoices that start with C as they are cancelled\n",
    "    clean_spark_df = clean_spark_df.filter(~col(\"Invoice\").startswith(\"C\"))\n",
    "\n",
    "    return clean_spark_df\n",
    "\n",
    "\n",
    "clean_retails1_spark = clean_df(retails1_spark)\n",
    "clean_retails2_spark = clean_df(retails2_spark)\n",
    "\n",
    "print(clean_retails1_spark.count(), clean_retails2_spark.count())\n",
    "# save clean data\n",
    "output_path = 'online_retail_IIs1_clean.parquet'\n",
    "clean_retails1_spark.write.mode(\"overwrite\").parquet(output_path)\n",
    "\n",
    "output_path = 'online_retail_IIs2_clean.parquet'\n",
    "clean_retails2_spark.write.mode(\"overwrite\").parquet(output_path)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b24a74-6fd6-41f8-a3c8-dd096bbf2bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
